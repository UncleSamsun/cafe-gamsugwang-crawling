""" 
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì´ìš©í•˜ì—¬ ì§€ì •ëœ ì§€ë¦¬ì  ì˜ì—­ ë‚´ ì¹´í˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , 
ìˆ˜ì§‘ëœ ì¹´í˜ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 
ì£¼ìš” ê¸°ëŠ¥ìœ¼ë¡œëŠ” API ìš”ì²­ ì„¸ì…˜ ìƒì„±, ì¹´í˜ ê²€ìƒ‰, ê²°ê³¼ ì €ì¥, ê·¸ë¦¬ê³  ê·¸ë¦¬ë“œ ê¸°ë°˜ í¬ë¡¤ë§ ì‹¤í–‰ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
"""

import requests
import pandas as pd
import time
import json
from requests.adapters import HTTPAdapter
from urllib3.util import Retry
import os
from app.core.db import get_connection


def create_session():
    """
    ì¬ì‹œë„ ì •ì±…ì´ ì ìš©ëœ requests ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ë©°, 
    ì•ˆì •ì ì¸ API í˜¸ì¶œì„ ìœ„í•´ HTTPAdapterë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    session = requests.Session()
    retries = Retry(
        total=5,
        backoff_factor=0.5,
        status_forcelist=[500, 502, 503, 504]
    )
    session.mount('https://', HTTPAdapter(max_retries=retries))
    return session


def search_cafes(min_lat, min_lng, max_lat, max_lng, api_key, session):
    """
    ì§€ì •ëœ ì¢Œí‘œ ë²”ìœ„ ë‚´ì—ì„œ ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì´ìš©í•´ ì¹´í˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        min_lat (float): ìµœì†Œ ìœ„ë„
        min_lng (float): ìµœì†Œ ê²½ë„
        max_lat (float): ìµœëŒ€ ìœ„ë„
        max_lng (float): ìµœëŒ€ ê²½ë„
        api_key (str): ì¹´ì¹´ì˜¤ API í‚¤
        session (requests.Session): ì¬ì‚¬ìš© ê°€ëŠ¥í•œ HTTP ì„¸ì…˜ ê°ì²´
    
    Returns:
        list[dict]: ê²€ìƒ‰ëœ ì¹´í˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    headers = {
        "Authorization": f"KakaoAK {api_key}",
        "Content-Type": "application/json; charset=utf-8"
    }

    cafe_ids = set()
    cafe_data = []
    page = 1

    while True:
        try:
            # API í˜¸ì¶œ: ì¹´í…Œê³ ë¦¬ë³„ ì¹´í˜ ê²€ìƒ‰ ìš”ì²­ êµ¬ì„±
            url = "https://dapi.kakao.com/v2/local/search/category.json"
            params = {
                "category_group_code": "CE7",  # ì¹´í˜ ì¹´í…Œê³ ë¦¬ ì½”ë“œ
                "rect": f"{min_lng},{min_lat},{max_lng},{max_lat}",
                "page": page,
                "size": 15
            }

            print(f"API ìš”ì²­ ì¤‘: í˜ì´ì§€ {page}")

            response = session.get(url, headers=headers, params=params)

            # API í‚¤ ì¸ì¦ ì˜¤ë¥˜ ì²˜ë¦¬
            if response.status_code in (401, 403):
                print(f"API í‚¤ ì¸ì¦ ì˜¤ë¥˜ ë°œìƒ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
                print("ìƒˆë¡œìš´ API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                return cafe_data

            response.raise_for_status()
            result = response.json()

            # ì‘ë‹µì—ì„œ ì¹´í˜ ë°ì´í„° ì¶”ì¶œ
            documents = result.get("documents", [])
            if not documents:
                print("ë” ì´ìƒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break

            for document in documents:
                cafe_id = document.get("id")
                place_name = document.get("place_name")
                x = document.get("x")
                y = document.get("y")
                if cafe_id and place_name and x and y:
                    if cafe_id not in cafe_ids:
                        cafe_ids.add(cafe_id)
                        cafe_data.append({
                            "cafe_id": cafe_id,
                            "place_name": place_name,
                            "x": float(x),
                            "y": float(y)
                        })

            print(f"{page}í˜ì´ì§€ ì™„ë£Œ: ì´ {len(cafe_ids)}ê°œ ì¹´í˜ ìˆ˜ì§‘ë¨")

            # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
            if result.get("meta", {}).get("is_end", True):
                print("ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break
            else:
                page += 1
                time.sleep(1)  # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ

        except requests.exceptions.RequestException as e:
            # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„
            print(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}")
            time.sleep(2)
            continue
        except Exception as e:
            # ê¸°íƒ€ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì²˜ë¦¬
            print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

    return cafe_data


def save_results(results, filename):
    """
    ìˆ˜ì§‘ëœ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        results (list[dict]): ì €ì¥í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        filename (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def save_cafe_ids(grid_key: str, cafe_data: list[dict]):
    """
    ìˆ˜ì§‘ëœ ì¹´í˜ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    ì¤‘ë³µëœ IDëŠ” ë¬´ì‹œí•˜ë©°, ì €ì¥ í›„ ì „ì²´ ì €ì¥ëœ ì¹´í˜ ìˆ˜ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        grid_key (str): í˜„ì¬ ê·¸ë¦¬ë“œ ì˜ì—­ ì‹ë³„ í‚¤
        cafe_data (list[dict]): ì €ì¥í•  ì¹´í˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not cafe_data:
        print(f"{grid_key} ì˜ì—­ì—ì„œ ìˆ˜ì§‘ëœ ì¹´í˜ ì •ë³´ê°€ ì—†ì–´ ì €ì¥ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return

    conn = get_connection()
    cursor = conn.cursor()
    for cafe in cafe_data:
        try:
            cursor.execute(
                "INSERT IGNORE INTO cafe_ids (id, place_name, x, y) VALUES (%s, %s, %s, %s)",
                (cafe["cafe_id"], cafe["place_name"], cafe["x"], cafe["y"])
            )
        except Exception as e:
            print(f"âŒ DB ì‚½ì… ì‹¤íŒ¨: {e}")
    conn.commit()
    print(f"{grid_key} ì˜ì—­ ì €ì¥ ì™„ë£Œ ({len(cafe_data)}ê°œ ë°ì´í„° ì €ì¥ë¨)")

    cursor.execute("SELECT COUNT(*) AS total FROM cafe_ids")
    total = cursor.fetchone()["total"]
    print(f"í˜„ì¬ê¹Œì§€ ì €ì¥ëœ ì „ì²´ ì¹´í˜ ìˆ˜: {total}")

    cursor.close()
    conn.close()


def run_grid_crawling():
    """
    ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ë¶„í• ëœ ì˜ì—­ë³„ë¡œ ì¹´í˜ ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜¤ë©°, ê° ì˜ì—­ë³„ë¡œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    Returns:
        dict: ì €ì¥ëœ ê³ ìœ  ì¹´í˜ ID ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    API_KEY = os.getenv("KAKAO_API_KEY", "")
    if not API_KEY:
        raise EnvironmentError("KAKAO_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    session = create_session()
    place_ids = set()

    # cafe_ids í…Œì´ë¸” ì´ˆê¸°í™”
    conn = get_connection()
    with conn.cursor() as cursor:
        cursor.execute("DELETE FROM cafe_ids")
        print("ğŸ”„ cafe_ids í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ")
    conn.commit()
    conn.close()

    grid_rects = pd.read_csv("data/map/grid_jeju_rects_200m_filtered.csv")
    print(f"ì´ ê²€ìƒ‰í•  ì‚¬ê°í˜• ì˜ì—­ ìˆ˜: {len(grid_rects)}")

    for idx, row in grid_rects.iterrows():
        min_lat, min_lng = row["min_lat"], row["min_lng"]
        max_lat, max_lng = row["max_lat"], row["max_lng"]
        grid_key = f"{min_lat:.6f},{min_lng:.6f},{max_lat:.6f},{max_lng:.6f}"

        print(f"\n[{idx + 1}/{len(grid_rects)}] ì˜ì—­ ê²€ìƒ‰ ì‹œì‘: {grid_key}")
        cafe_data = search_cafes(min_lat, min_lng, max_lat, max_lng, API_KEY, session)
        save_cafe_ids(grid_key, cafe_data)
        place_ids.update([cafe["cafe_id"] for cafe in cafe_data])

    print(f"\nì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(place_ids)}ê°œì˜ ê³ ìœ  ì¹´í˜ ID ì €ì¥ë¨")
    return {"saved": len(place_ids)}


def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ê·¸ë¦¬ë“œ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    result = run_grid_crawling()
    print(f"í¬ë¡¤ë§ ê²°ê³¼: {result}")


if __name__ == "__main__":
    main()