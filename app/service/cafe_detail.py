"""
ì´ ëª¨ë“ˆì€ ì¹´ì¹´ì˜¤ë§µì—ì„œ íŠ¹ì • ì¹´í˜ì˜ ìƒì„¸ ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ê³ ,
ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import time
import re
import math
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
import os
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from app.core.db import get_connection
from app.core.redis_client import get_redis

DEFAULT_WAIT = 5
SHORT_WAIT = 3

def crawl_and_save_single_cafe(cafe_id):
    """
    ë‹¨ì¼ ì¹´í˜ IDë¥¼ ë°›ì•„ ì¹´ì¹´ì˜¤ë§µì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ê³ ,
    ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    # Specify Chromium binary location
    options.binary_location = "/usr/bin/chromium"
    service = ChromeService(executable_path="/usr/bin/chromedriver")
    driver = webdriver.Chrome(service=service, options=options)
    try:
        url = f"https://place.map.kakao.com/{cafe_id}"
        driver.get(url)

        # í˜ì´ì§€ ë¡œë”© ë° ê¸°ë³¸ ì •ë³´ ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(driver, DEFAULT_WAIT).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
            name_elem = WebDriverWait(driver, DEFAULT_WAIT * 2).until(
                EC.visibility_of_element_located((By.CSS_SELECTOR, "h3.tit_place"))
            )
            name = name_elem.text.strip()
        except:
            print(f"âŒ {cafe_id} - 'tit_place' ìš”ì†Œ ì—†ìŒ (ë¡œë”© ëŒ€ê¸° í›„ ì‹¤íŒ¨)")
            driver.quit()
            return False

        # ì£¼ì†Œ ì •ë³´ ìˆ˜ì§‘
        try:
            address = WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "span.txt_detail"))
            ).text.strip()
        except:
            address = None

        # ì „í™”ë²ˆí˜¸ ì •ë³´ ìˆ˜ì§‘
        phone = None
        try:
            phone_sections = WebDriverWait(driver, DEFAULT_WAIT).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.unit_default"))
            )
        except:
            phone_sections = []
        for section in phone_sections:
            try:
                title_elem = section.find_element(By.CSS_SELECTOR, "h5.tit_info span.ico_call2")
                if title_elem and "ì „í™”" in title_elem.text:
                    phone = section.find_element(By.CSS_SELECTOR, "span.txt_detail").text.strip()
                    break
            except:
                continue

        # ì˜ì—…ì‹œê°„ ì •ë³´ í™•ì¥ ë° ìˆ˜ì§‘
        try:
            try:
                fold_buttons = driver.find_elements(By.CSS_SELECTOR, "button.btn_fold")
                for btn in fold_buttons:
                    if btn.get_attribute("aria-expanded") == "false":
                        btn.click()
                        WebDriverWait(driver, SHORT_WAIT).until(
                            lambda d: btn.get_attribute("aria-expanded") == "true"
                        )
            except:
                pass
            lines = WebDriverWait(driver, DEFAULT_WAIT).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.line_fold"))
            )
            open_hours = []
            for line in lines:
                try:
                    day = line.find_element(By.CSS_SELECTOR, "span.tit_fold").text.strip()
                    detail = line.find_element(By.CSS_SELECTOR, "span.txt_detail").text.strip()
                    open_hours.append(f"{day}: {detail}")
                except:
                    continue
            open_time = "; ".join(open_hours)
        except:
            open_time = None

        # í‰ì  ìˆ˜ì§‘
        try:
            rating = float(WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "span.num_star"))
            ).text.strip())
        except:
            rating = 0.0

        # ë¦¬ë·° ìˆ˜ì§‘
        try:
            review_count = int(WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "span.info_num"))
            ).text.strip().replace("ê°œ", ""))
        except:
            review_count = 0

        # í‰ì ê³¼ ë¦¬ë·° ìˆ˜ì˜ ì¼ê´€ì„± í™•ì¸
        if review_count == 0 and rating > 0.0:
            rating = 0.0

        # ë©”ë‰´ íƒ­ í´ë¦­ ë° ë©”ë‰´ ì •ë³´ ìˆ˜ì§‘
        try:
            menu_tab = driver.find_element(By.LINK_TEXT, "ë©”ë‰´")
            menu_tab.click()
            time.sleep(1)
        except:
            pass
        try:
            menu_elements = WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul.list_goods > li"))
            )
        except:
            menu_elements = []
        menus = []
        for m in menu_elements:
            try:
                menu_name = m.find_element(By.CSS_SELECTOR, "strong.tit_item").text.strip()
                menu_price_raw = m.find_element(By.CSS_SELECTOR, "p.desc_item").text.strip()
                menu_price = re.sub(r"[^\d]", "", menu_price_raw)
                try:
                    img_tag = m.find_element(By.CSS_SELECTOR, "img.img_goods")
                    menu_image_url = img_tag.get_attribute("src")
                    if menu_image_url.startswith("//"):
                        menu_image_url = "https:" + menu_image_url
                except:
                    menu_image_url = None
                menus.append((cafe_id, menu_name, int(menu_price), menu_image_url))
            except:
                continue

        # ìš°í¸ë²ˆí˜¸ ì¶”ì¶œ
        zipcode = None
        zipcode_match = re.search(r'\(ìš°\)?(\d{5})', address if address else "")
        if zipcode_match:
            zipcode = zipcode_match.group(1)

        # ëŒ€í‘œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        image_url = None
        try:
            thumb_img = WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "img.img-thumb.img_cfit"))
            )
            image_url = thumb_img.get_attribute("src")
            if image_url.startswith("//"):
                image_url = "https:" + image_url
        except:
            pass

        # DBì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¡°íšŒ
        conn = get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT x, y FROM cafe_ids WHERE id = %s", (cafe_id,))
        loc_result = cursor.fetchone()
        lon = loc_result["x"] if loc_result else None
        lat = loc_result["y"] if loc_result else None

        # ì¹´í˜ ì •ë³´ DBì— ì €ì¥ (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)
        cursor.execute("""
            INSERT INTO cafes (id, title, address, open_time, rate, rate_count, image_url, zipcode, phone_number, lat, lon)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE title=VALUES(title), address=VALUES(address), open_time=VALUES(open_time), rate=VALUES(rate),
            rate_count=VALUES(rate_count), image_url=VALUES(image_url), zipcode=VALUES(zipcode),
            phone_number=VALUES(phone_number), lat=VALUES(lat), lon=VALUES(lon)
        """, (cafe_id, name, address, open_time, rating, review_count, image_url, zipcode, phone, lat, lon))

        # í›„ê¸° íƒ­ í´ë¦­ ë° í›„ê¸° ì •ë³´ ìˆ˜ì§‘
        try:
            review_tab = driver.find_element(By.LINK_TEXT, "í›„ê¸°")
            review_tab.click()
            time.sleep(1)
            last_height = driver.execute_script("return document.body.scrollHeight")
            while True:
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
                new_height = driver.execute_script("return document.body.scrollHeight")
                if new_height == last_height:
                    break
                last_height = new_height
        except:
            pass

        try:
            review_elements = WebDriverWait(driver, SHORT_WAIT).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul.list_review > li"))
            )
        except:
            review_elements = []

        for el in review_elements:
            try:
                star_tag = el.find_element(By.CSS_SELECTOR, "div.info_grade > span.starred_grade > span.screen_out:nth-of-type(2)")
                star = float(star_tag.get_attribute("textContent").strip())
                try:
                    content_tag = el.find_element(By.CSS_SELECTOR, "div.wrap_review p.desc_review")
                    content = content_tag.text.strip()
                    for suffix in ["ë”ë³´ê¸°", "ì ‘ê¸°"]:
                        if content.endswith(suffix):
                            content = content[:-len(suffix)].strip()
                except:
                    continue
                cursor.execute("""
                    INSERT INTO kakao_reviews (cafe_id, content, rating)
                    VALUES (%s, %s, %s)
                """, (cafe_id, content, star))
            except:
                continue

        # ë©”ë‰´ ì •ë³´ DBì— ì €ì¥
        for m in menus:
            cursor.execute("""
                INSERT INTO menus (cafe_id, name, price, menu_image_url)
                VALUES (%s, %s, %s, %s)
            """, m)

        # ì»¤ë°‹ ë° ì—°ê²° ì¢…ë£Œ
        conn.commit()
        cursor.close()
        conn.close()

        print(f"âœ… cafeId:{cafe_id} ì €ì¥ ì™„ë£Œ")
        driver.quit()
        return True

    except Exception as e:
        print(f"âŒ cafeId:{cafe_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        driver.quit()
        return False


def crawl_all_cafes(job_id: str, update_progress_callback):
    """
    ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ëª¨ë“  ì¹´í˜ IDë¥¼ ì¡°íšŒí•˜ì—¬,
    ê° ì¹´í˜ì˜ ìƒì„¸ ì •ë³´ë¥¼ í¬ë¡¤ë§í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    ì‹¤íŒ¨í•œ ì¹´í˜ IDëŠ” ì¬ì‹œë„í•˜ë©° ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ë° ì´ˆê¸°í™”
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("DELETE FROM kakao_reviews")
    cursor.execute("DELETE FROM menus")
    cursor.execute("DELETE FROM keywords")
    cursor.execute("DELETE FROM cafes")
    cursor.execute("ALTER TABLE kakao_reviews AUTO_INCREMENT = 1")
    cursor.execute("ALTER TABLE menus AUTO_INCREMENT = 1")
    cursor.execute("ALTER TABLE keywords AUTO_INCREMENT = 1")
    cursor.execute("ALTER TABLE cafes AUTO_INCREMENT = 1")
    conn.commit()

    start_time = time.time()

    # ëª¨ë“  ì¹´í˜ ID ì¡°íšŒ
    cursor.execute("SELECT DISTINCT id FROM cafe_ids")
    cafe_ids = [row["id"] for row in cursor.fetchall()]
    cursor.close()
    conn.close()

    total_ids = len(cafe_ids)
    processed_count = 0

    print(f"ì´ {total_ids}ê°œì˜ ì¹´í˜ IDë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")

    saved_count = 0
    failed_ids = []

    # ë³‘ë ¬ë¡œ í¬ë¡¤ë§ ìˆ˜í–‰
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(crawl_and_save_single_cafe, cafe_id): cafe_id for cafe_id in cafe_ids}
        for future in as_completed(futures):
            cafe_id = futures[future]
            result = future.result()
            processed_count += 1
            percent = int(processed_count / total_ids * 100)
            update_progress_callback(percent, f"detail_step_{processed_count}")
            if result:
                saved_count += 1
            else:
                failed_ids.append(cafe_id)

    # ì‹¤íŒ¨í•œ í•­ëª© ì¬ì‹œë„
    if failed_ids:
        print(f"ğŸ” {len(failed_ids)}ê°œ í•­ëª© ì¬ì‹œë„ ì¤‘...")
        with ThreadPoolExecutor(max_workers=5) as retry_executor:
            retry_futures = {retry_executor.submit(crawl_and_save_single_cafe, cafe_id): cafe_id for cafe_id in failed_ids}
            for future in as_completed(retry_futures):
                cafe_id = retry_futures[future]
                result = future.result()
                processed_count += 1
                percent = int(processed_count / total_ids * 100)
                update_progress_callback(percent, f"detail_step_{processed_count}")
                if result:
                    saved_count += 1
                    failed_ids.remove(cafe_id)

    elapsed_time = time.time() - start_time
    print(f"â± í¬ë¡¤ë§ ì™„ë£Œ - ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
    print(f"âœ… ì €ì¥ëœ ì¹´í˜ ìˆ˜: {saved_count} / {total_ids}")
    if failed_ids:
        print("âŒ ì‹¤íŒ¨í•œ ì¹´í˜ ID ëª©ë¡:")
        print(", ".join(map(str, failed_ids)))

    update_progress_callback(100, "completed")
    return {"crawled_cafes": saved_count, "failed_ids": failed_ids}


async def cafe_detail_job(job_id: str, update_progress_callback: callable):
    """
    Background task wrapper to run crawl_all_cafes in a thread.
    """
    try:
        await asyncio.to_thread(crawl_all_cafes, job_id, update_progress_callback)
    except Exception as e:
        # on error, let caller handle setting failure status
        raise e